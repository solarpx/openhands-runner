# OpenHands Configuration Example
# Recommended: Add these to your ~/.zshrc or ~/.bashrc instead of using .env files

# Required: Your LLM API key
OPENHANDS_LLM_API_KEY="your_api_key_here"

# Optional: LLM Configuration
OPENHANDS_LLM_MODEL="claude-3-5-sonnet-20241022"  # Default model
OPENHANDS_LLM_BASE_URL="https://api.anthropic.com/v1"  # Default API endpoint

# Examples for other LLM providers:
#OPENHANDS_LLM_MODEL="gpt-4"                      # OpenAI GPT-4
#OPENHANDS_LLM_BASE_URL="https://api.openai.com"  # OpenAI API

#OPENHANDS_LLM_MODEL="gpt-4"                      # Azure OpenAI
#OPENHANDS_LLM_BASE_URL="https://your-endpoint.openai.azure.com"
#OPENHANDS_LLM_API_VERSION="2024-02-15-preview"   # Azure API version

#OPENHANDS_LLM_MODEL="llama2"                     # Local Ollama model
#OPENHANDS_LLM_BASE_URL="http://localhost:11434"  # Ollama API

# Optional: API Rate Limiting (defaults shown)
#LLM_NUM_RETRIES=4          # Number of retry attempts
#LLM_RETRY_MIN_WAIT=5       # Minimum wait between retries (seconds)
#LLM_RETRY_MAX_WAIT=30      # Maximum wait between retries (seconds)
#LLM_RETRY_MULTIPLIER=2     # Multiplier for exponential backoff